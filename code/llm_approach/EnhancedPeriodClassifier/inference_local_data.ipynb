{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook showing how to make predictions with a trained model for sub-event detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import relevant libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /users/eleves-a/2024/tim-\n",
      "[nltk_data]     luka.horstmann.m2/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import json\n",
    "import sys\n",
    "\n",
    "sys.path.append('../.')\n",
    "from preprocessor import filter_tweet\n",
    "import EnhancedPeriodClassifier.train as train\n",
    "\n",
    "# if sentiment analysis is needed\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/Data/tlh45/'   # directory where the HF models will be saved, and where the challenge data is stored\n",
    "MODEL_DIR = 'Model'     # directory where the model as well as the normalization params to be used are saved (obtained from training)\n",
    "MAX_TWEETS = 1500           # maximum number of tweets per period to be considered\n",
    "BATCH_SIZE = 32             # batch size for the model, depending on the GPU memory\n",
    "\n",
    "EMBEDDING_DIM = 768         # dimension of the embeddings (BERT-base)\n",
    "MAX_LENGTH = 128            #maximum number of tokens in a tweet\n",
    "\n",
    "# CHOOSE WHICH MODEL TO USE (\"normal\" version or \"modified\" version)\n",
    "from enhancedperiodclassifier_modified import EnhancedPeriodClassifier\n",
    "# from enhancedperiodclassifier import EnhancedPeriodClassifier\n",
    "\n",
    "# Define output directory for predictions\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "output_dir = os.path.join(\"..\", \"..\", \"..\", \"predictions\", f\"preds-{today}\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "normalization_params_path = os.path.join(MODEL_DIR, \"normalization_params.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function Definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_and_normalize_features_sentiment(tweets, period_id, normalization_params):\n",
    "    num_tweets = len(tweets)\n",
    "    if num_tweets > 0:\n",
    "        avg_tweet_length = np.mean([len(str(tweet)) for tweet in tweets])\n",
    "        avg_sentiment = train.compute_sentiment_scores(tweets, sia)\n",
    "    else:\n",
    "        avg_tweet_length = 0\n",
    "        avg_sentiment = 0\n",
    "\n",
    "    num_tweets_norm = (num_tweets - normalization_params['num_tweets_mean']) / normalization_params['num_tweets_std']\n",
    "    avg_tweet_length_norm = (avg_tweet_length - normalization_params['avg_tweet_length_mean']) / normalization_params['avg_tweet_length_std']\n",
    "    normalized_period = (period_id - normalization_params['periodID_mean']) / normalization_params['periodID_std']\n",
    "    normalized_sentiment = (avg_sentiment - normalization_params['sentiment_mean']) / normalization_params['sentiment_std']\n",
    "\n",
    "    return num_tweets_norm, avg_tweet_length_norm, normalized_period, normalized_sentiment\n",
    "\n",
    "def compute_and_normalize_features(tweets, period_id, normalization_params):\n",
    "    num_tweets = len(tweets)\n",
    "    if num_tweets > 0:\n",
    "        avg_tweet_length = np.mean([len(str(tweet)) for tweet in tweets])\n",
    "    else:\n",
    "        avg_tweet_length = 0\n",
    "\n",
    "    num_tweets_norm = (num_tweets - normalization_params['num_tweets_mean']) / normalization_params['num_tweets_std']\n",
    "    avg_tweet_length_norm = (avg_tweet_length - normalization_params['avg_tweet_length_mean']) / normalization_params['avg_tweet_length_std']\n",
    "    normalized_period = (period_id - normalization_params['periodID_mean']) / normalization_params['periodID_std']\n",
    "\n",
    "    return num_tweets_norm, avg_tweet_length_norm, normalized_period\n",
    "\n",
    "def prepare_embeddings_and_masks(tweets, tokenizer, bertweet_model, device):\n",
    "    if len(tweets) > MAX_TWEETS:\n",
    "        tweets = tweets[:MAX_TWEETS]\n",
    "        mask = [1] * MAX_TWEETS\n",
    "    else:\n",
    "        mask = [1] * len(tweets) + [0] * (MAX_TWEETS - len(tweets))\n",
    "        tweets += [tokenizer.pad_token] * (MAX_TWEETS - len(tweets))\n",
    "\n",
    "    # embeddings = train.compute_mean_embeddings_batch(tweets, bertweet_model=bertweet_model, tokenizer=tokenizer, device=device, max_length=MAX_LENGTH)\n",
    "    # OR (experimental)\n",
    "    embeddings = train.compute_cls_embeddings_batch(tweets, bertweet_model=bertweet_model, tokenizer=tokenizer, device=device, max_length=MAX_LENGTH)\n",
    "\n",
    "    return embeddings, mask\n",
    "\n",
    "def predict_batch(tweets_batch, period_ids, normalization_params, tokenizer, bertweet_model, model, device):\n",
    "    num_tweets_norm = []\n",
    "    avg_tweet_length_norm = []\n",
    "    normalized_period = []\n",
    "    normalized_sentiment = []\n",
    "    for tweets, period_id in zip(tweets_batch, period_ids):\n",
    "        nt_norm, at_norm, np_norm = compute_and_normalize_features(tweets, period_id, normalization_params) # choose this line instead of below if sentiment analysis is not needed\n",
    "        # nt_norm, at_norm, np_norm, ns_norm = compute_and_normalize_features_sentiment(tweets, period_id, normalization_params)\n",
    "        num_tweets_norm.append(nt_norm)\n",
    "        avg_tweet_length_norm.append(at_norm)\n",
    "        normalized_period.append(np_norm)\n",
    "        # normalized_sentiment.append(ns_norm) # with sentiment\n",
    "\n",
    "    embeddings_batch = []\n",
    "    masks_batch = []\n",
    "    for tweets in tweets_batch:\n",
    "        embeddings, mask = prepare_embeddings_and_masks(tweets, tokenizer, bertweet_model, device)\n",
    "        embeddings_batch.append(embeddings)\n",
    "        masks_batch.append(mask)\n",
    "\n",
    "    embeddings_tensor = torch.tensor(np.stack(embeddings_batch), dtype=torch.float32).to(device) \n",
    "    masks_tensor = torch.tensor(np.stack(masks_batch), dtype=torch.float32).to(device) \n",
    "    additional_features = torch.tensor([\n",
    "        [nt, at, np,] for nt, at, np in zip(num_tweets_norm, avg_tweet_length_norm, normalized_period) #  choose this line instead of below if sentiment analysis is not needed\n",
    "        # [nt, at, np, ns] for nt, at, np, ns in zip(num_tweets_norm, avg_tweet_length_norm, normalized_period, normalized_sentiment) # with sentiment\n",
    "    ], dtype=torch.float32).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            embeddings=embeddings_tensor,\n",
    "            masks=masks_tensor,\n",
    "            additional_features=additional_features\n",
    "        )\n",
    "        logits = outputs['logits']\n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        predictions = torch.argmax(probabilities, dim=-1)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return predictions.cpu().numpy(), probabilities.cpu().numpy()[:, 1]\n",
    "\n",
    "def group_evaluation_data(df):\n",
    "    grouped = df.groupby('ID').agg({\n",
    "        'MatchID': 'first',\n",
    "        'PeriodID': 'first',\n",
    "        'Tweet': list \n",
    "    }).reset_index()\n",
    "    return grouped\n",
    "\n",
    "def load_and_preprocess_eval_data(eval_path):\n",
    "    df = pd.read_csv(eval_path)\n",
    "    df = df.drop_duplicates(subset=['Tweet'])\n",
    "    df['Tweet'] = df['Tweet'].apply(filter_tweet)\n",
    "    df = df.dropna(subset=['Tweet']).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def load_predictions(directory):\n",
    "    all_data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.startswith(\"predictions_\") and filename.endswith(\".csv\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            df = pd.read_csv(filepath)\n",
    "            all_data.append(df)\n",
    "    return pd.concat(all_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 768\n",
      "Number of classes: 2\n",
      "Number of attention heads: 8\n",
      "Dropout probability: 0.5\n",
      "Additional features dimension: 3\n",
      "FC1 dimension: 4096\n",
      "Model loaded successfully!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d0d8f52d8814513a87fbbb7571dde41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing evaluation files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "430bb817cdf640c0b689245c248ba423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating GermanyGhana32.csv:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2024/tim-luka.horstmann.m2/ml-data-challenge-2024/code/llm_approach/EnhancedPeriodClassifier/.././EnhancedPeriodClassifier/train.py:183: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), autocast(enabled=True):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64e80c1047a4480d81505232ace0af2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating GreeceIvoryCoast44.csv:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2024/tim-luka.horstmann.m2/ml-data-challenge-2024/code/llm_approach/EnhancedPeriodClassifier/.././EnhancedPeriodClassifier/train.py:183: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), autocast(enabled=True):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b9c6820548c420eb46a67773c9e7ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating NetherlandsMexico64.csv:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2024/tim-luka.horstmann.m2/ml-data-challenge-2024/code/llm_approach/EnhancedPeriodClassifier/.././EnhancedPeriodClassifier/train.py:183: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), autocast(enabled=True):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23cffd5339c4715b0e103f6374d6e88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating GermanySerbia2010.csv:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2024/tim-luka.horstmann.m2/ml-data-challenge-2024/code/llm_approach/EnhancedPeriodClassifier/.././EnhancedPeriodClassifier/train.py:183: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), autocast(enabled=True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference completed. Predictions saved to: ../../predictions/preds-2024-12-11\n",
      "Combined predictions saved to ../../predictions/preds-2024-12-11/predictions.csv\n",
      "EventType\n",
      "1    282\n",
      "0    234\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "try:\n",
    "    model = EnhancedPeriodClassifier.from_pretrained(MODEL_DIR)\n",
    "    model.to(device).eval()\n",
    "    print(\"Model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    exit()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'vinai/bertweet-base',\n",
    "    cache_dir=os.path.join(DATA_DIR, \"hf_cache\"),\n",
    "    normalization=True,\n",
    "    use_fast=False\n",
    ")\n",
    "bertweet_model = AutoModel.from_pretrained(\n",
    "    'vinai/bertweet-base',\n",
    "    cache_dir=os.path.join(DATA_DIR, \"hf_cache\")\n",
    ")\n",
    "bertweet_model.to(device).eval()\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "if not os.path.exists(normalization_params_path):\n",
    "    raise FileNotFoundError(f\"Normalization parameters not found at {normalization_params_path}\")\n",
    "\n",
    "with open(normalization_params_path, 'r') as f:\n",
    "    normalization_params = json.load(f)\n",
    "\n",
    "eval_dir = os.path.join(DATA_DIR, \"challenge_data\", \"eval_tweets\")\n",
    "for eval_file in tqdm(os.listdir(eval_dir), desc=\"Processing evaluation files\"):\n",
    "    if eval_file.endswith(\".csv\"):\n",
    "        eval_path = os.path.join(eval_dir, eval_file)\n",
    "        df = load_and_preprocess_eval_data(eval_path)\n",
    "        grouped = group_evaluation_data(df)\n",
    "\n",
    "        tweets_list = grouped['Tweet'].tolist()\n",
    "        period_ids = grouped['PeriodID'].tolist()\n",
    "\n",
    "        predictions = []\n",
    "        probabilities = []\n",
    "\n",
    "        for i in tqdm(range(0, len(tweets_list), BATCH_SIZE), desc=f\"Evaluating {eval_file}\"):\n",
    "            batch_tweets = tweets_list[i:i + BATCH_SIZE]\n",
    "            batch_period_ids = period_ids[i:i + BATCH_SIZE]\n",
    "\n",
    "            preds, probs = predict_batch(\n",
    "                batch_tweets, batch_period_ids, normalization_params, tokenizer, bertweet_model, model, device\n",
    "            )\n",
    "            predictions.extend(preds)\n",
    "            probabilities.extend(probs)\n",
    "\n",
    "        grouped['EventType'] = predictions\n",
    "        grouped['Probability'] = probabilities\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"predictions_{eval_file}\")\n",
    "        grouped.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Inference completed. Predictions saved to:\", output_dir)\n",
    "\n",
    "df_predictions = load_predictions(output_dir)\n",
    "combined_output_path = os.path.join(output_dir, \"predictions.csv\")\n",
    "df_predictions.to_csv(combined_output_path, index=False)\n",
    "\n",
    "print(f\"Combined predictions saved to {combined_output_path}\")\n",
    "print(df_predictions['EventType'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare predictions for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>EventType</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6_0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>['I Finally get to see Germany play\\n#GER   ðŸ‡©ðŸ‡ª...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.187946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6_1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>['\"In a few minutes #BigGame of #GER x #GHA......</td>\n",
       "      <td>0</td>\n",
       "      <td>0.348002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6_10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>['Ghana invented the gravity bong #WorldCup #f...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6_100</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>['THIS GAME. #GhanavsGermany #WorldCup', \"Let'...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.959938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6_101</td>\n",
       "      <td>6</td>\n",
       "      <td>101</td>\n",
       "      <td>['Klose! You come on the pitch, the ball goes ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.952688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>15_95</td>\n",
       "      <td>15</td>\n",
       "      <td>95</td>\n",
       "      <td>['Want Mexico to win just for their goal keepe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.262070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>15_96</td>\n",
       "      <td>15</td>\n",
       "      <td>96</td>\n",
       "      <td>[\"I'm gonna go laugh to my netherlands uncle's...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.124372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>15_97</td>\n",
       "      <td>15</td>\n",
       "      <td>97</td>\n",
       "      <td>['Put chicharito in pleaseee ! #CH14 #mex', 'D...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.112108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>15_98</td>\n",
       "      <td>15</td>\n",
       "      <td>98</td>\n",
       "      <td>['Dirk Kuyt must be one of the fittest players...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.119479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>15_99</td>\n",
       "      <td>15</td>\n",
       "      <td>99</td>\n",
       "      <td>['Not liking the clock #ned', 'Wow wtf are you...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.606523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>516 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  MatchID  PeriodID  \\\n",
       "0      6_0        6         0   \n",
       "1      6_1        6         1   \n",
       "2     6_10        6        10   \n",
       "3    6_100        6       100   \n",
       "4    6_101        6       101   \n",
       "..     ...      ...       ...   \n",
       "511  15_95       15        95   \n",
       "512  15_96       15        96   \n",
       "513  15_97       15        97   \n",
       "514  15_98       15        98   \n",
       "515  15_99       15        99   \n",
       "\n",
       "                                                 Tweet  EventType  Probability  \n",
       "0    ['I Finally get to see Germany play\\n#GER   ðŸ‡©ðŸ‡ª...          0     0.187946  \n",
       "1    ['\"In a few minutes #BigGame of #GER x #GHA......          0     0.348002  \n",
       "2    ['Ghana invented the gravity bong #WorldCup #f...          1     0.944888  \n",
       "3    ['THIS GAME. #GhanavsGermany #WorldCup', \"Let'...          1     0.959938  \n",
       "4    ['Klose! You come on the pitch, the ball goes ...          1     0.952688  \n",
       "..                                                 ...        ...          ...  \n",
       "511  ['Want Mexico to win just for their goal keepe...          0     0.262070  \n",
       "512  [\"I'm gonna go laugh to my netherlands uncle's...          0     0.124372  \n",
       "513  ['Put chicharito in pleaseee ! #CH14 #mex', 'D...          0     0.112108  \n",
       "514  ['Dirk Kuyt must be one of the fittest players...          0     0.119479  \n",
       "515  ['Not liking the clock #ned', 'Wow wtf are you...          1     0.606523  \n",
       "\n",
       "[516 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>EventType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6_3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6_4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>16_125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>16_126</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>16_127</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>16_128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>16_129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>516 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  EventType\n",
       "0       6_0          0\n",
       "1       6_1          0\n",
       "2       6_2          0\n",
       "3       6_3          0\n",
       "4       6_4          0\n",
       "..      ...        ...\n",
       "511  16_125          1\n",
       "512  16_126          1\n",
       "513  16_127          1\n",
       "514  16_128          1\n",
       "515  16_129          1\n",
       "\n",
       "[516 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# order by periodID, then by MatchID\n",
    "df = df_predictions.copy()\n",
    "df = df.sort_values(by=['MatchID', 'PeriodID']).reset_index(drop=True)\n",
    "df = df[['ID', 'EventType']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to ../predictions/preds-2024-12-08/filtered_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "submission_path = os.path.join(output_dir, \"filtered_predictions.csv\")\n",
    "df.to_csv(submission_path, index=False)\n",
    "print(f\"Submission file saved to {submission_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
